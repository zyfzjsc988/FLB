{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T09:19:40.143497Z",
     "start_time": "2018-08-08T09:19:38.753501Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "# train data\n",
    "summary_folder_path = '../../datasets/train_data/summary'\n",
    "mining_folder_path = '../../datasets/train_data/data_mining'\n",
    "result_path = '../../datasets/results'\n",
    "games = { 'baseball':'/baseball/mlb',\n",
    "         'iceball': '/iceball/nhl',\n",
    "         'soccer_champion':'/soccer/champ_league',\n",
    "         'scoccer_england':'/soccer/epl',\n",
    "         'soccer_major':'/soccer/majorleague'}\n",
    "# folder name is games, result name is games_results.csv\n",
    "\n",
    "games_list = ['baseball','iceball']\n",
    "soccer_list = ['soccer_champion','scoccer_england','soccer_major']\n",
    "\n",
    "soccer_features_name = ['maximum', 'minimum', 'ave', 'ave_normalized', \n",
    "            'start', 'start_normalized', 'end', 'end_normalized', 'start2end',\n",
    "            'start2end_normalized', 'start2max', 'start2max_normalized', 'start2min', 'start2min_normalized', \n",
    "            'std', 'no_price', 'length', \n",
    "            'up_num', 'down_num', 'up_rate', 'down_rate', 'duration', \n",
    "            'bias_max', 'bias_min', 'bias_ave', 'bias_st', 'draw_odds','away_odds']\n",
    "\n",
    "games_features_name = ['maximum', 'minimum', 'ave', 'ave_normalized', \n",
    "            'start', 'start_normalized', 'end', 'end_normalized', 'start2end',\n",
    "            'start2end_normalized', 'start2max', 'start2max_normalized', 'start2min', 'start2min_normalized', \n",
    "            'std', 'no_price', 'length', \n",
    "            'up_num', 'down_num', 'up_rate', 'down_rate', 'duration', \n",
    "            'bias_max', 'bias_min', 'bias_ave', 'bias_st']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. models\n",
    "logistic regression,\n",
    "KNN, \n",
    "Naive Bayes,\n",
    "DT,\n",
    "RF,\n",
    "AdaBoost,\n",
    "Gradient tree boosting,\n",
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T11:04:19.761873Z",
     "start_time": "2018-08-08T11:04:19.391870Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput: \\ntraining: matrix of features, target: two or three target\\nvalidate: matrix of features, target: two or three target\\n\\noutput: \\nacc, auc, or others\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input: \n",
    "training: matrix of features, target: two or three target\n",
    "validate: matrix of features, target: two or three target\n",
    "\n",
    "output: \n",
    "acc, auc, or others\n",
    "\"\"\"\n",
    "\n",
    "#  train ml models\n",
    "# input: features and labels\n",
    "# output: all acc\n",
    "def predict_soccer_result(features, label):\n",
    "    acc_dic = {}\n",
    "#     knn\n",
    "    knn = make_pipeline(preprocessing.StandardScaler(), KNeighborsClassifier(n_neighbors=60))\n",
    "    acc_dic['knn'] = cross_val_score(knn, features, label, cv=5).max()\n",
    "#     logistic regression\n",
    "    logreg = make_pipeline(preprocessing.StandardScaler(), LogisticRegression(C=0.3))\n",
    "    acc_dic['logistic_regression'] = cross_val_score(logreg, features, label, cv=5).max()\n",
    "#     naive bayes\n",
    "    bayes = make_pipeline(preprocessing.StandardScaler(), BernoulliNB())\n",
    "    acc_dic['bayes'] = cross_val_score(bayes, features, label, cv=5).max()\n",
    "#     decision tree   \n",
    "    dt = make_pipeline(preprocessing.StandardScaler(), DecisionTreeClassifier(random_state=0,max_depth=2))\n",
    "    acc_dic['decision_tree'] = cross_val_score(dt, features, label, cv=5).max()\n",
    "#     random forest\n",
    "    rf = make_pipeline(preprocessing.StandardScaler(), RandomForestClassifier(max_depth=5, random_state=0))\n",
    "    acc_dic['random_forest'] = cross_val_score(rf, features, label, cv=5).max()\n",
    "#     adaboost\n",
    "    adaboost = make_pipeline(preprocessing.StandardScaler(), AdaBoostClassifier(n_estimators=230))\n",
    "    acc_dic['AdaBoost'] = cross_val_score(adaboost, features, label, cv=5).max()\n",
    "#     gradient boosting\n",
    "    gb = make_pipeline(preprocessing.StandardScaler(),\n",
    "                        GradientBoostingClassifier(n_estimators=240, \n",
    "                                                   learning_rate=1.0,\n",
    "                                                   max_depth=1, \n",
    "                                                   random_state=0))\n",
    "    acc_dic['GradientBoosting'] = cross_val_score(gb, features, label, cv=5).max()    \n",
    "\n",
    "    return acc_dic\n",
    "\n",
    "\n",
    "def regression_next(features,label):\n",
    "    mse_dic = {}\n",
    "#     lasso\n",
    "    alpha = 0.02\n",
    "    lasso = make_pipeline(preprocessing.StandardScaler(), Lasso(alpha=alpha))\n",
    "    mse_dic['lasso'] = cross_val_score(lasso, features, label, scoring='r2', cv=5).max()\n",
    "#     elasticnet\n",
    "    elasticnet = make_pipeline(preprocessing.StandardScaler(), ElasticNet(alpha=alpha, l1_ratio=0.7))\n",
    "    mse_dic['ElasticNet'] = cross_val_score(elasticnet, features, label, scoring='r2', cv=5).max()   \n",
    "#     bayes regression\n",
    "    bayesianRidge = make_pipeline(preprocessing.StandardScaler(), BayesianRidge())\n",
    "    mse_dic['BayesianRidge'] = cross_val_score(bayesianRidge, features, label, scoring='r2', cv=5).max()     \n",
    "#     svm regression\n",
    "    bayesisanRidge = make_pipeline(preprocessing.StandardScaler(), BayesianRidge())\n",
    "    mse_dic['BayesianRidge'] = cross_val_score(bayesianRidge, features, label, scoring='r2', cv=5).max()   \n",
    "    \n",
    "    svm.SVR(C=0.01+0.001*i)\n",
    "    return mse_dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T09:28:24.068136Z",
     "start_time": "2018-08-08T09:28:13.854129Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.672093023255814"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6604651162790698"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6616279069767442"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6604651162790698"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "risk_value = 'no_risk'\n",
    "labels = target['home'].apply(int).values\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec_name = [i+tag for i in soccer_features_name]\n",
    "#     adaboost\n",
    "for i in range(1,5):\n",
    "    adaboost = make_pipeline(preprocessing.StandardScaler(), \n",
    "                             MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                                           hidden_layer_sizes=(2*i, ), random_state=1))\n",
    "    cross_val_score(adaboost, unbiased[sec_name].values, labels, cv=5).max()\n",
    "# results_1 = pd.read_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## soccer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T09:20:26.323785Z",
     "start_time": "2018-08-08T09:20:26.124783Z"
    },
    "code_folding": [
     0,
     12
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_guess(sec_no,series):\n",
    "    count = 0\n",
    "    for i in series.index.tolist():\n",
    "        if series.loc[i,'end'+sec_no] > series.loc[i,'draw_odds'+sec_no] and \\\n",
    "        series.loc[i,'end'+sec_no] > series.loc[i,'away_odds'+sec_no]:\n",
    "            if int(series.loc[i,'home']) == 1:\n",
    "                count +=1\n",
    "        else:\n",
    "            if int(series.loc[i,'home']) == 0:\n",
    "                count +=1\n",
    "    return count/len(unbiased)\n",
    "\n",
    "def summary(sec_name,sec_no):\n",
    "    results = pd.DataFrame()\n",
    "    dic = predict_soccer_result(unbiased[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,unbiased)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'unbiased'\n",
    "    results = results.append(pred)\n",
    "\n",
    "    dic = predict_soccer_result(hourly_corrected[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,hourly_corrected)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'hourly_corrected'\n",
    "    results = results.append(pred)\n",
    "    \n",
    "    dic = predict_soccer_result(daily_corrected[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,daily_corrected)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'daily_corrected'\n",
    "    results = results.append(pred)\n",
    "\n",
    "    dic = predict_soccer_result(global_corrected[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,global_corrected)\n",
    "    pred = pd.Series(dic) \n",
    "    pred.name = 'global_corrected'\n",
    "    results = results.append(pred)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T09:20:29.062780Z",
     "start_time": "2018-08-08T09:20:27.660781Z"
    },
    "code_folding": [],
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surface\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# soccer\n",
    "game_name = 'soccer'\n",
    "\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "# all target home, draw , away\n",
    "target = unbiased[['home','draw','away']]\n",
    "target['target'] = (target['home']+target['draw']*2+target['away']*3).apply(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T21:39:19.546140Z",
     "start_time": "2018-08-07T21:26:58.842842Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n",
      "sec3 to predict:\n",
      "all to predict:\n",
      "all features to predict:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# risk analysis\n",
    "# high risk index / low risk index\n",
    "\n",
    "risk_value = 'no_risk'\n",
    "labels = target['home'].apply(int).values\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in soccer_features_name])\n",
    "all_features.extend([i+'_2' for i in soccer_features_name])\n",
    "all_features.extend([i+'_3' for i in soccer_features_name])\n",
    "all_features.extend([i+'_all' for i in soccer_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T22:25:21.090597Z",
     "start_time": "2018-08-07T22:15:43.950029Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surface\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3180"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n",
      "sec3 to predict:\n",
      "all to predict:\n",
      "all features to predict:\n"
     ]
    }
   ],
   "source": [
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# all target home, draw , away\n",
    "target = unbiased[['home','draw','away']]\n",
    "target['target'] = (target['home']+target['draw']*2+target['away']*3).apply(int)\n",
    "\n",
    "\n",
    "risk_value = 'high_risk'\n",
    "high_risk = unbiased[((unbiased['start_all']<0.7) & (unbiased['start_all']>0.3))].index.tolist()\n",
    "len(high_risk)\n",
    "unbiased = unbiased.loc[high_risk]\n",
    "hourly_corrected = hourly_corrected.loc[high_risk]\n",
    "daily_corrected = daily_corrected.loc[high_risk]\n",
    "global_corrected = global_corrected.loc[high_risk]\n",
    "target = target.loc[high_risk]\n",
    "labels = target['home'].apply(int).values\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in soccer_features_name])\n",
    "all_features.extend([i+'_2' for i in soccer_features_name])\n",
    "all_features.extend([i+'_3' for i in soccer_features_name])\n",
    "all_features.extend([i+'_all' for i in soccer_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T22:30:15.850553Z",
     "start_time": "2018-08-07T22:25:22.759590Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surface\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1115"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n",
      "sec3 to predict:\n",
      "all to predict:\n",
      "all features to predict:\n"
     ]
    }
   ],
   "source": [
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# all target home, draw , away\n",
    "target = unbiased[['home','draw','away']]\n",
    "target['target'] = (target['home']+target['draw']*2+target['away']*3).apply(int)\n",
    "\n",
    "\n",
    "risk_value = 'low_risk'\n",
    "high_risk = unbiased[((unbiased['start_all']>=0.7) | (unbiased['start_all']<=0.3))].index.tolist()\n",
    "len(high_risk)\n",
    "unbiased = unbiased.loc[high_risk]\n",
    "hourly_corrected = hourly_corrected.loc[high_risk]\n",
    "daily_corrected = daily_corrected.loc[high_risk]\n",
    "global_corrected = global_corrected.loc[high_risk]\n",
    "target = target.loc[high_risk]\n",
    "labels = target['home'].apply(int).values\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in soccer_features_name])\n",
    "all_features.extend([i+'_2' for i in soccer_features_name])\n",
    "all_features.extend([i+'_3' for i in soccer_features_name])\n",
    "all_features.extend([i+'_all' for i in soccer_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iceball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T22:33:13.203041Z",
     "start_time": "2018-08-07T22:33:13.104039Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_guess(sec_no,series):\n",
    "    count = 0\n",
    "    for i in series.index.tolist():\n",
    "        if series.loc[i,'end'+sec_no] >= 0.5:\n",
    "            if int(series.loc[i,'home']) == 1:\n",
    "                count +=1\n",
    "        else:\n",
    "            if int(series.loc[i,'home']) == 0:\n",
    "                count +=1\n",
    "    return count/len(unbiased)\n",
    "\n",
    "def summary(sec_name,sec_no):\n",
    "    results = pd.DataFrame()\n",
    "    dic = predict_soccer_result(unbiased[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,unbiased)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'unbiased'\n",
    "    results = results.append(pred)\n",
    "\n",
    "    dic = predict_soccer_result(hourly_corrected[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,hourly_corrected)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'hourly_corrected'\n",
    "    results = results.append(pred)\n",
    "    \n",
    "    dic = predict_soccer_result(daily_corrected[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,daily_corrected)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'daily_corrected'\n",
    "    results = results.append(pred)\n",
    "\n",
    "    dic = predict_soccer_result(global_corrected[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,global_corrected)\n",
    "    pred = pd.Series(dic) \n",
    "    pred.name = 'global_corrected'\n",
    "    results = results.append(pred)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T22:40:26.275679Z",
     "start_time": "2018-08-07T22:38:52.114065Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "286"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n",
      "sec3 to predict:\n",
      "all to predict:\n",
      "all features to predict:\n"
     ]
    }
   ],
   "source": [
    "game_name = 'iceball'\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# all target home, draw , away\n",
    "target = unbiased['home']\n",
    "\n",
    "risk_value = 'low_risk'\n",
    "high_risk = unbiased[((unbiased['start_all']>=0.7) | (unbiased['start_all']<=0.3))].index.tolist()\n",
    "len(high_risk)\n",
    "unbiased = unbiased.loc[high_risk]\n",
    "hourly_corrected = hourly_corrected.loc[high_risk]\n",
    "daily_corrected = daily_corrected.loc[high_risk]\n",
    "global_corrected = global_corrected.loc[high_risk]\n",
    "target = target.loc[high_risk]\n",
    "labels = unbiased['home'].apply(int).values\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in games_features_name])\n",
    "all_features.extend([i+'_2' for i in games_features_name])\n",
    "all_features.extend([i+'_3' for i in games_features_name])\n",
    "all_features.extend([i+'_all' for i in games_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T23:01:45.097724Z",
     "start_time": "2018-08-07T22:41:08.934543Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6663"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n",
      "sec3 to predict:\n",
      "all to predict:\n",
      "all features to predict:\n"
     ]
    }
   ],
   "source": [
    "game_name = 'iceball'\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# all target home, draw , away\n",
    "target = unbiased['home']\n",
    "\n",
    "risk_value = 'high_risk'\n",
    "high_risk = unbiased[((unbiased['start_all']<0.7) & (unbiased['start_all']>0.3))].index.tolist()\n",
    "len(high_risk)\n",
    "unbiased = unbiased.loc[high_risk]\n",
    "hourly_corrected = hourly_corrected.loc[high_risk]\n",
    "daily_corrected = daily_corrected.loc[high_risk]\n",
    "global_corrected = global_corrected.loc[high_risk]\n",
    "target = target.loc[high_risk]\n",
    "labels = unbiased['home'].apply(int).values\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in games_features_name])\n",
    "all_features.extend([i+'_2' for i in games_features_name])\n",
    "all_features.extend([i+'_3' for i in games_features_name])\n",
    "all_features.extend([i+'_all' for i in games_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T23:22:41.549646Z",
     "start_time": "2018-08-07T23:01:46.530642Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n",
      "sec3 to predict:\n",
      "all to predict:\n",
      "all features to predict:\n"
     ]
    }
   ],
   "source": [
    "game_name = 'iceball'\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# all target home, draw , away\n",
    "target = unbiased['home']\n",
    "\n",
    "risk_value = 'no_risk'\n",
    "\n",
    "labels = unbiased['home'].apply(int).values\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in games_features_name])\n",
    "all_features.extend([i+'_2' for i in games_features_name])\n",
    "all_features.extend([i+'_3' for i in games_features_name])\n",
    "all_features.extend([i+'_all' for i in games_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseball"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T23:58:53.876901Z",
     "start_time": "2018-08-07T23:22:42.839636Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n",
      "sec3 to predict:\n",
      "all to predict:\n",
      "all features to predict:\n"
     ]
    }
   ],
   "source": [
    "game_name = 'baseball'\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# all target home, draw , away\n",
    "target = unbiased['home']\n",
    "\n",
    "risk_value = 'no_risk'\n",
    "\n",
    "labels = unbiased['home'].apply(int).values\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in games_features_name])\n",
    "all_features.extend([i+'_2' for i in games_features_name])\n",
    "all_features.extend([i+'_3' for i in games_features_name])\n",
    "all_features.extend([i+'_all' for i in games_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T00:29:18.311961Z",
     "start_time": "2018-08-07T23:58:55.953900Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11743"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n",
      "sec3 to predict:\n",
      "all to predict:\n",
      "all features to predict:\n"
     ]
    }
   ],
   "source": [
    "game_name = 'baseball'\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# all target home, draw , away\n",
    "target = unbiased['home']\n",
    "\n",
    "risk_value = 'high_risk'\n",
    "high_risk = unbiased[((unbiased['start_all']<0.7) & (unbiased['start_all']>0.3))].index.tolist()\n",
    "len(high_risk)\n",
    "unbiased = unbiased.loc[high_risk]\n",
    "hourly_corrected = hourly_corrected.loc[high_risk]\n",
    "daily_corrected = daily_corrected.loc[high_risk]\n",
    "global_corrected = global_corrected.loc[high_risk]\n",
    "target = target.loc[high_risk]\n",
    "labels = unbiased['home'].apply(int).values\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in games_features_name])\n",
    "all_features.extend([i+'_2' for i in games_features_name])\n",
    "all_features.extend([i+'_3' for i in games_features_name])\n",
    "all_features.extend([i+'_all' for i in games_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T00:30:59.388939Z",
     "start_time": "2018-08-08T00:29:19.775903Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "318"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n",
      "sec3 to predict:\n",
      "all to predict:\n",
      "all features to predict:\n"
     ]
    }
   ],
   "source": [
    "game_name = 'baseball'\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# all target home, draw , away\n",
    "target = unbiased['home']\n",
    "\n",
    "risk_value = 'low_risk'\n",
    "high_risk = unbiased[((unbiased['start_all']>=0.7) | (unbiased['start_all']<=0.3))].index.tolist()\n",
    "len(high_risk)\n",
    "unbiased = unbiased.loc[high_risk]\n",
    "hourly_corrected = hourly_corrected.loc[high_risk]\n",
    "daily_corrected = daily_corrected.loc[high_risk]\n",
    "global_corrected = global_corrected.loc[high_risk]\n",
    "target = target.loc[high_risk]\n",
    "labels = unbiased['home'].apply(int).values\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in games_features_name])\n",
    "all_features.extend([i+'_2' for i in games_features_name])\n",
    "all_features.extend([i+'_3' for i in games_features_name])\n",
    "all_features.extend([i+'_all' for i in games_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### predict direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T10:08:27.015883Z",
     "start_time": "2018-08-08T10:00:57.322882Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n"
     ]
    }
   ],
   "source": [
    "def direction_find(x):\n",
    "    if x>0:\n",
    "        return 1\n",
    "    elif x==0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "def summary_direction_results(sec_name,sec_no,next_no):\n",
    "    results = pd.DataFrame()\n",
    "    target = (unbiased['end'+next_no] - unbiased['end'+sec_no]).apply(direction_find)\n",
    "    dic = predict_soccer_result(unbiased[sec_name].values, target)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'unbiased'\n",
    "    results = results.append(pred)\n",
    "\n",
    "    \n",
    "#     target = (hourly_corrected['end'+next_no] - hourly_corrected['end'+sec_no]).apply(direction_find)\n",
    "    dic = predict_soccer_result(hourly_corrected[sec_name].values, target)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'hourly_corrected'\n",
    "    results = results.append(pred)\n",
    "\n",
    "#     target = (daily_corrected['end'+next_no] - daily_corrected['end'+sec_no]).apply(direction_find)\n",
    "    dic = predict_soccer_result(daily_corrected[sec_name].values, target)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'daily_corrected'\n",
    "    results = results.append(pred)\n",
    "\n",
    "#     target = (global_corrected['end'+next_no] - global_corrected['end'+sec_no]).apply(direction_find)\n",
    "    dic = predict_soccer_result(global_corrected[sec_name].values, target)\n",
    "    pred = pd.Series(dic) \n",
    "    pred.name = 'global_corrected'\n",
    "    results = results.append(pred)\n",
    "    return results\n",
    "\n",
    "# soccer\n",
    "game_name = 'soccer'\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary_direction_results(sec_name,tag,'_2')\n",
    "results_1.to_csv(result_path+'/direction/'+game_name+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary_direction_results(sec_name,tag,'_3')\n",
    "results_1.to_csv(result_path+'/direction/'+game_name+tag+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T10:16:29.662299Z",
     "start_time": "2018-08-08T10:08:27.493890Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n"
     ]
    }
   ],
   "source": [
    "# iceball\n",
    "game_name = 'iceball'\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary_direction_results(sec_name,tag,'_2')\n",
    "results_1.to_csv(result_path+'/direction/'+game_name+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary_direction_results(sec_name,tag,'_3')\n",
    "results_1.to_csv(result_path+'/direction/'+game_name+tag+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T10:28:43.664412Z",
     "start_time": "2018-08-08T10:16:30.059260Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n"
     ]
    }
   ],
   "source": [
    "# baseball\n",
    "game_name = 'baseball'\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary_direction_results(sec_name,tag,'_2')\n",
    "results_1.to_csv(result_path+'/direction/'+game_name+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in games_features_name]\n",
    "results_1 = summary_direction_results(sec_name,tag,'_3')\n",
    "results_1.to_csv(result_path+'/direction/'+game_name+tag+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### regression: next period price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T10:46:50.647688Z",
     "start_time": "2018-08-08T10:46:49.516694Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary_price_results(sec_name,sec_no,next_no):\n",
    "    results = pd.DataFrame()\n",
    "    target = unbiased['end'+sec_no]\n",
    "    dic = regression_next(unbiased[sec_name].values, target.values)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'unbiased'\n",
    "    results = results.append(pred)\n",
    "\n",
    "    \n",
    "#     target = (hourly_corrected['end'+next_no] - hourly_corrected['end'+sec_no]).apply(direction_find)\n",
    "    dic = regression_next(hourly_corrected[sec_name].values, target.values)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'hourly_corrected'\n",
    "    results = results.append(pred)\n",
    "\n",
    "#     target = (daily_corrected['end'+next_no] - daily_corrected['end'+sec_no]).apply(direction_find)\n",
    "    dic = regression_next(daily_corrected[sec_name].values, target.values)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'daily_corrected'\n",
    "    results = results.append(pred)\n",
    "\n",
    "#     target = (global_corrected['end'+next_no] - global_corrected['end'+sec_no]).apply(direction_find)\n",
    "    dic = regression_next(global_corrected[sec_name].values, target.values)\n",
    "    pred = pd.Series(dic) \n",
    "    pred.name = 'global_corrected'\n",
    "    results = results.append(pred)\n",
    "    return results\n",
    "\n",
    "# soccer\n",
    "game_name = 'soccer'\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T11:07:06.835631Z",
     "start_time": "2018-08-08T11:06:54.008978Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6735249458937265"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6722008864667706"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.671626605458456"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-423fd8dc1826>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.02\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlasso\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVR\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mC\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlasso\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munbiased\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msec_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0munbiased\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'end_2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    340\u001b[0m                                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                                 pre_dispatch=pre_dispatch)\n\u001b[0m\u001b[0;32m    343\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score)\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_train_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             return_times=True)\n\u001b[1;32m--> 206\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;31m# _score will return dict if is_multimetric is True\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \"\"\"\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m     99\u001b[0m         super(_PredictScorer, self).__call__(estimator, X, y_true,\n\u001b[0;32m    100\u001b[0m                                              sample_weight=sample_weight)\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             return self._sign * self._score_func(y_true, y_pred,\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_final_estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m             cache_size=self.cache_size)\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sec_name = [i+'_1' for i in soccer_features_name]\n",
    "for i in range(1,10):\n",
    "    alpha = 0.02\n",
    "    lasso = make_pipeline(preprocessing.StandardScaler(), svm.SVR(C=0.01+0.001*i))\n",
    "    cross_val_score(lasso, unbiased[sec_name].values, unbiased['end_2'], scoring='r2', cv=5).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "379px",
    "left": "718.267px",
    "right": "20px",
    "top": "122px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
