{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T21:16:07.127315Z",
     "start_time": "2018-08-07T21:16:07.092339Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "# train data\n",
    "summary_folder_path = '../../datasets/train_data/summary'\n",
    "mining_folder_path = '../../datasets/train_data/data_mining'\n",
    "result_path = '../../datasets/results'\n",
    "games = { 'baseball':'/baseball/mlb',\n",
    "         'iceball': '/iceball/nhl',\n",
    "         'soccer_champion':'/soccer/champ_league',\n",
    "         'scoccer_england':'/soccer/epl',\n",
    "         'soccer_major':'/soccer/majorleague'}\n",
    "# folder name is games, result name is games_results.csv\n",
    "\n",
    "games_list = ['baseball','iceball']\n",
    "soccer_list = ['soccer_champion','scoccer_england','soccer_major']\n",
    "\n",
    "soccer_features_name = ['maximum', 'minimum', 'ave', 'ave_normalized', \n",
    "            'start', 'start_normalized', 'end', 'end_normalized', 'start2end',\n",
    "            'start2end_normalized', 'start2max', 'start2max_normalized', 'start2min', 'start2min_normalized', \n",
    "            'std', 'no_price', 'length', \n",
    "            'up_num', 'down_num', 'up_rate', 'down_rate', 'duration', \n",
    "            'bias_max', 'bias_min', 'bias_ave', 'bias_st', 'draw_odds','away_odds']\n",
    "\n",
    "games_features_name = ['maximum', 'minimum', 'ave', 'ave_normalized', \n",
    "            'start', 'start_normalized', 'end', 'end_normalized', 'start2end',\n",
    "            'start2end_normalized', 'start2max', 'start2max_normalized', 'start2min', 'start2min_normalized', \n",
    "            'std', 'no_price', 'length', \n",
    "            'up_num', 'down_num', 'up_rate', 'down_rate', 'duration', \n",
    "            'bias_max', 'bias_min', 'bias_ave', 'bias_st']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. models\n",
    "logistic regression,\n",
    "KNN, \n",
    "Naive Bayes,\n",
    "DT,\n",
    "RF,\n",
    "AdaBoost,\n",
    "Gradient tree boosting,\n",
    "ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T20:36:51.648467Z",
     "start_time": "2018-08-07T20:36:51.445466Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput: \\ntraining: matrix of features, target: two or three target\\nvalidate: matrix of features, target: two or three target\\n\\noutput: \\nacc, auc, or others\\n'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\"\"\"\n",
    "input: \n",
    "training: matrix of features, target: two or three target\n",
    "validate: matrix of features, target: two or three target\n",
    "\n",
    "output: \n",
    "acc, auc, or others\n",
    "\"\"\"\n",
    "\n",
    "#  train ml models\n",
    "# input: features and labels\n",
    "# output: all acc\n",
    "def predict_soccer_result(features, label):\n",
    "    acc_dic = {}\n",
    "#     knn\n",
    "    knn = make_pipeline(preprocessing.StandardScaler(), KNeighborsClassifier(n_neighbors=60))\n",
    "    acc_dic['knn'] = cross_val_score(knn, features, label, cv=5).max()\n",
    "#     logistic regression\n",
    "    logreg = make_pipeline(preprocessing.StandardScaler(), LogisticRegression(C=0.3))\n",
    "    acc_dic['logistic_regression'] = cross_val_score(logreg, features, label, cv=5).max()\n",
    "#     naive bayes\n",
    "    bayes = make_pipeline(preprocessing.StandardScaler(), BernoulliNB())\n",
    "    acc_dic['bayes'] = cross_val_score(bayes, features, label, cv=5).max()\n",
    "#     decision tree   \n",
    "    dt = make_pipeline(preprocessing.StandardScaler(), DecisionTreeClassifier(random_state=0,max_depth=2))\n",
    "    acc_dic['decision_tree'] = cross_val_score(dt, features, label, cv=5).max()\n",
    "#     random forest\n",
    "    rf = make_pipeline(preprocessing.StandardScaler(), RandomForestClassifier(max_depth=5, random_state=0))\n",
    "    acc_dic['random_forest'] = cross_val_score(rf, features, label, cv=5).max()\n",
    "#     adaboost\n",
    "    adaboost = make_pipeline(preprocessing.StandardScaler(), AdaBoostClassifier(n_estimators=230))\n",
    "    acc_dic['AdaBoost'] = cross_val_score(adaboost, features, label, cv=5).max()\n",
    "#     gradient boosting\n",
    "    gb = make_pipeline(preprocessing.StandardScaler(),\n",
    "                        GradientBoostingClassifier(n_estimators=240, \n",
    "                                                   learning_rate=1.0,\n",
    "                                                   max_depth=1, \n",
    "                                                   random_state=0))\n",
    "    acc_dic['GradientBoosting'] = cross_val_score(gb, features, label, cv=5).max()    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return acc_dic\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T21:26:50.461161Z",
     "start_time": "2018-08-07T21:26:50.304186Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_guess(sec_no,series):\n",
    "    count = 0\n",
    "    for i in series.index.tolist():\n",
    "        if series.loc[i,'end'+sec_no] > series.loc[i,'draw_odds'+sec_no] and \\\n",
    "        series.loc[i,'end'+sec_no] > series.loc[i,'away_odds'+sec_no]:\n",
    "            if int(series.loc[i,'home']) == 1:\n",
    "                count +=1\n",
    "        else:\n",
    "            if int(series.loc[i,'home']) == 0:\n",
    "                count +=1\n",
    "    return count/len(unbiased)\n",
    "\n",
    "def summary(sec_name,sec_no):\n",
    "    results = pd.DataFrame()\n",
    "    dic = predict_soccer_result(unbiased[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,unbiased)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'unbiased'\n",
    "    results = results.append(pred)\n",
    "\n",
    "    dic = predict_soccer_result(hourly_corrected[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,hourly_corrected)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'hourly_corrected'\n",
    "    results = results.append(pred)\n",
    "    \n",
    "    dic = predict_soccer_result(daily_corrected[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,daily_corrected)\n",
    "    pred = pd.Series(dic)\n",
    "    pred.name = 'daily_corrected'\n",
    "    results = results.append(pred)\n",
    "\n",
    "    dic = predict_soccer_result(global_corrected[sec_name].values, labels)\n",
    "    dic['odds_guess'] = random_guess(sec_no,global_corrected)\n",
    "    pred = pd.Series(dic) \n",
    "    pred.name = 'global_corrected'\n",
    "    results = results.append(pred)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T18:47:26.309573Z",
     "start_time": "2018-08-07T18:47:24.823572Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surface\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# soccer\n",
    "game_name = 'soccer'\n",
    "\n",
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "# all target home, draw , away\n",
    "target = unbiased[['home','draw','away']]\n",
    "target['target'] = (target['home']+target['draw']*2+target['away']*3).apply(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T21:39:19.546140Z",
     "start_time": "2018-08-07T21:26:58.842842Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n",
      "sec3 to predict:\n",
      "all to predict:\n",
      "all features to predict:\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# risk analysis\n",
    "# high risk index / low risk index\n",
    "\n",
    "risk_value = 'no_risk'\n",
    "labels = target['home'].apply(int).values\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in soccer_features_name])\n",
    "all_features.extend([i+'_2' for i in soccer_features_name])\n",
    "all_features.extend([i+'_3' for i in soccer_features_name])\n",
    "all_features.extend([i+'_all' for i in soccer_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-08-07T22:15:43.947Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\surface\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3180"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sec1 to predict:\n",
      "sec2 to predict:\n",
      "sec3 to predict:\n"
     ]
    }
   ],
   "source": [
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# all target home, draw , away\n",
    "target = unbiased[['home','draw','away']]\n",
    "target['target'] = (target['home']+target['draw']*2+target['away']*3).apply(int)\n",
    "\n",
    "\n",
    "risk_value = 'high_risk'\n",
    "high_risk = unbiased[((unbiased['start_all']<0.7) & (unbiased['start_all']>0.3))].index.tolist()\n",
    "len(high_risk)\n",
    "unbiased = unbiased.loc[high_risk]\n",
    "hourly_corrected = hourly_corrected.loc[high_risk]\n",
    "daily_corrected = daily_corrected.loc[high_risk]\n",
    "global_corrected = global_corrected.loc[high_risk]\n",
    "target = target.loc[high_risk]\n",
    "labels = target['home'].apply(int).values\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in soccer_features_name])\n",
    "all_features.extend([i+'_2' for i in soccer_features_name])\n",
    "all_features.extend([i+'_3' for i in soccer_features_name])\n",
    "all_features.extend([i+'_all' for i in soccer_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unbiased = pd.read_csv(mining_folder_path+'/'+game_name+'_unbiased.csv').iloc[:,1:].fillna(0)\n",
    "hourly_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_hourly_corrected.csv').iloc[:,1:].fillna(0)\n",
    "daily_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_daily_corrected.csv').iloc[:,1:].fillna(0)\n",
    "global_corrected = pd.read_csv(mining_folder_path+'/'+game_name+'_global_corrected.csv').iloc[:,1:].fillna(0)\n",
    "\n",
    "# all target home, draw , away\n",
    "target = unbiased[['home','draw','away']]\n",
    "target['target'] = (target['home']+target['draw']*2+target['away']*3).apply(int)\n",
    "\n",
    "\n",
    "risk_value = 'low_risk'\n",
    "high_risk = unbiased[((unbiased['start_all']>0.7) | (unbiased['start_all']<0.3))].index.tolist()\n",
    "len(high_risk)\n",
    "unbiased = unbiased.loc[high_risk]\n",
    "hourly_corrected = hourly_corrected.loc[high_risk]\n",
    "daily_corrected = daily_corrected.loc[high_risk]\n",
    "global_corrected = global_corrected.loc[high_risk]\n",
    "target = target.loc[high_risk]\n",
    "labels = target['home'].apply(int).values\n",
    "\n",
    "# sec1\n",
    "print('sec1 to predict:')\n",
    "tag = '_1'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# sec2\n",
    "print('sec2 to predict:')\n",
    "tag = '_2'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# # sec3\n",
    "print('sec3 to predict:')\n",
    "tag = '_3'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "# all\n",
    "print('all to predict:')\n",
    "tag = '_all'\n",
    "sec1_name = [i+tag for i in soccer_features_name]\n",
    "results_1 = summary(sec1_name,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'.csv')\n",
    "\n",
    "print('all features to predict:')\n",
    "tag = '_all'\n",
    "all_features =[]\n",
    "all_features.extend([i+'_1' for i in soccer_features_name])\n",
    "all_features.extend([i+'_2' for i in soccer_features_name])\n",
    "all_features.extend([i+'_3' for i in soccer_features_name])\n",
    "all_features.extend([i+'_all' for i in soccer_features_name])\n",
    "results_1 = summary(all_features,tag)\n",
    "results_1.to_csv(result_path+'/home_win/'+game_name+'/'+risk_value+tag+'features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-07T22:15:22.222283Z",
     "start_time": "2018-08-07T22:15:22.215289Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48238993710691824"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.sum()/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "379px",
    "left": "718.267px",
    "right": "20px",
    "top": "122px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
